{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train , y_train),(x_test , y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[67])\n",
    "y_train[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising the data\n",
    "input_shape = (28,28,1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buliding CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D ,MaxPooling2D , Flatten , Dense , Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(32,3,activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Conv2D(64,3,activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in conv2d first parameter is how many filters you want to use and 2 is for what is th size of filter\n",
    "# in Dense layer first parameter is how many output unit will generate when input_shape is given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 49s 816us/step - loss: 0.5165 - acc: 0.8424 - val_loss: 0.1010 - val_acc: 0.9713\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.1203 - acc: 0.9642 - val_loss: 0.0572 - val_acc: 0.9826\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 47s 788us/step - loss: 0.0837 - acc: 0.9745 - val_loss: 0.0418 - val_acc: 0.9864\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 48s 793us/step - loss: 0.0662 - acc: 0.9793 - val_loss: 0.0352 - val_acc: 0.9885\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 47s 789us/step - loss: 0.0575 - acc: 0.9825 - val_loss: 0.0299 - val_acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1724de6af28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=512,epochs=5,verbose=1,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 325us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02991067842299817, 0.9905]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1105814e-05, 1.6244158e-09, 7.8806102e-07, 1.1604422e-08,\n",
       "       7.6819909e-08, 4.4403793e-04, 9.9950004e-01, 3.3854020e-11,\n",
       "       3.3928107e-05, 4.0195804e-08], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[6785].argmax() == y_test[6785].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[4444].argmax() == y_test[4444].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1422].argmax() == y_test[1422].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-dbec55afc206>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m789\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (28, 28, 1)"
     ]
    }
   ],
   "source": [
    "model.predict(x_test[789])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single image test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=x_test[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z.reshape(1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4935656e-08, 2.2667439e-10, 1.7063238e-08, 1.5422813e-07,\n",
       "        5.7707075e-06, 6.0778476e-08, 1.4781929e-09, 8.0027312e-06,\n",
       "        3.5333403e-06, 9.9998248e-01]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[99].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[99].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x172497b2b70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[99].reshape(28,28),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
