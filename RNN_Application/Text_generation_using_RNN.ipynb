{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-generation-using-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0CYepU792PJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "e05ee59b-3d98-400c-d648-b8c35a0916bc"
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import get_file\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "import requests\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsFTcUep-IU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "fb6ffb18-bf5c-4449-9f10-316d2f42600f"
      },
      "source": [
        "r = requests.get(\"https://data.heatonresearch.com/data/t81-558/text/treasure_island.txt\")\n",
        "raw_text = r.text\n",
        "print(raw_text[0:1000])\n",
        "print(len(raw_text))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ï»¿The Project Gutenberg EBook of Treasure Island, by Robert Louis Stevenson\r\n",
            "\r\n",
            "This eBook is for the use of anyone anywhere at no cost and with\r\n",
            "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
            "re-use it under the terms of the Project Gutenberg License included\r\n",
            "with this eBook or online at www.gutenberg.net\r\n",
            "\r\n",
            "\r\n",
            "Title: Treasure Island\r\n",
            "\r\n",
            "Author: Robert Louis Stevenson\r\n",
            "\r\n",
            "Illustrator: Milo Winter\r\n",
            "\r\n",
            "Release Date: January 12, 2009 [EBook #27780]\r\n",
            "\r\n",
            "Language: English\r\n",
            "\r\n",
            "\r\n",
            "*** START OF THIS PROJECT GUTENBERG EBOOK TREASURE ISLAND ***\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "Produced by Juliet Sutherland, Stephen Blundell and the\r\n",
            "Online Distributed Proofreading Team at http://www.pgdp.net\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " THE ILLUSTRATED CHILDREN'S LIBRARY\r\n",
            "\r\n",
            "\r\n",
            "         _Treasure Island_\r\n",
            "\r\n",
            "       Robert Louis Stevenson\r\n",
            "\r\n",
            "          _Illustrated by_\r\n",
            "            Milo Winter\r\n",
            "\r\n",
            "\r\n",
            "           [Illustration]\r\n",
            "\r\n",
            "\r\n",
            "           GRAMERCY BOOKS\r\n",
            "              NEW YORK\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            " Foreword copyright Â© 1986 by Random House V\n",
            "397419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd9n9diU_mog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_text = raw_text.lower()\n",
        "processed_text = re.sub(r'[^\\x00-\\x7f]',r'', processed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL5dNnR4A1UM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a4e0361c-79ad-4d73-b46a-d157f48a3365"
      },
      "source": [
        "print('corpus length:', len(processed_text))\n",
        "\n",
        "chars = sorted(list(set(processed_text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 397400\n",
            "total chars: 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUdQCTyVA3zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3EmZxj2A-QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0, len(processed_text) - seq_length, 3):\n",
        "    # Define input and output sequences\n",
        "    # Input is the current character plus desired sequence length\n",
        "    in_seq = processed_text[i:i + seq_length]\n",
        "\n",
        "    # Out sequence is the initial character plus total sequence length\n",
        "    out_seq = processed_text[i + seq_length]\n",
        "\n",
        "    # We now convert list of characters to integers based on\n",
        "    # previously and add the values to our lists\n",
        "    x_data.append([char_indices[char] for char in in_seq])\n",
        "    y_data.append(char_indices[out_seq])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9uiV45LBOND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc5b7e06-c50f-40f4-e854-71dce703855d"
      },
      "source": [
        "n_patterns = len(x_data)\n",
        "print (\"Total Patterns:\", n_patterns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns: 132434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivbwI6oEBcUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d0526fc-fd82-4a73-ab55-6cb4098ac04f"
      },
      "source": [
        "len(y_data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB9CMoLxBf4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3728d6c3-c7be-405e-ce4d-f8305f2bf57f"
      },
      "source": [
        "print(x_data[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[53, 41, 38, 2, 49, 51, 48, 43, 38, 36, 53, 2, 40, 54, 53, 38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54], [2, 49, 51, 48, 43, 38, 36, 53, 2, 40, 54, 53, 38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2], [48, 43, 38, 36, 53, 2, 40, 54, 53, 38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2], [36, 53, 2, 40, 54, 53, 38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58], [40, 54, 53, 38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38], [38, 47, 35, 38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38, 2, 34, 47], [38, 51, 40, 2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38, 2, 34, 47, 58, 56, 41], [2, 38, 35, 48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38, 2, 34, 47, 58, 56, 41, 38, 51, 38], [48, 48, 44, 2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38, 2, 34, 47, 58, 56, 41, 38, 51, 38, 2, 34, 53], [2, 48, 39, 2, 53, 51, 38, 34, 52, 54, 51, 38, 2, 42, 52, 45, 34, 47, 37, 13, 2, 35, 58, 2, 51, 48, 35, 38, 51, 53, 2, 45, 48, 54, 42, 52, 2, 52, 53, 38, 55, 38, 47, 52, 48, 47, 1, 0, 1, 0, 53, 41, 42, 52, 2, 38, 35, 48, 48, 44, 2, 42, 52, 2, 39, 48, 51, 2, 53, 41, 38, 2, 54, 52, 38, 2, 48, 39, 2, 34, 47, 58, 48, 47, 38, 2, 34, 47, 58, 56, 41, 38, 51, 38, 2, 34, 53, 2, 47, 48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtznObLoBkEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73f5f57b-c823-44da-b93c-3ad9aa15dc7a"
      },
      "source": [
        "len(x_data[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIROk8XsBuTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.reshape(x_data, (n_patterns, seq_length, 1))\n",
        "X = X/float(len(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-qDgdbPCnk2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6521ac5a-7f06-44bd-d180-c25e0665ac35"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132434, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUR7DrwwCxOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b92d6636-b10d-4483-ea08-2fc6955cf3a5"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "y = np_utils.to_categorical(y_data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ICXPnrDO1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "332a9213-22e3-4495-ca76-e92ba756ef81"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132434, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YytHQbQ2DT3j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "8161120d-5f44-4589-8237-9a9b2f3bd078"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYLZuINzDhym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkLOieZxD3cn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "e03bc9e0-2b90-4cce-8e5d-79807019d924"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 128)               197120    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 60)                7740      \n",
            "=================================================================\n",
            "Total params: 994,364\n",
            "Trainable params: 994,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeL0WcMEEEa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "218c8a69-5038-4e0f-fd68-99e572dbe2aa"
      },
      "source": [
        "model.fit(X, y, batch_size=256, epochs=20)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 132434 samples\n",
            "Epoch 1/20\n",
            "132434/132434 [==============================] - 200s 2ms/sample - loss: 3.1079\n",
            "Epoch 2/20\n",
            "132434/132434 [==============================] - 194s 1ms/sample - loss: 2.9432\n",
            "Epoch 3/20\n",
            "132434/132434 [==============================] - 198s 1ms/sample - loss: 2.7535\n",
            "Epoch 4/20\n",
            "132434/132434 [==============================] - 206s 2ms/sample - loss: 2.6728\n",
            "Epoch 5/20\n",
            "132434/132434 [==============================] - 208s 2ms/sample - loss: 2.6211\n",
            "Epoch 6/20\n",
            "132434/132434 [==============================] - 211s 2ms/sample - loss: 2.5786\n",
            "Epoch 7/20\n",
            "132434/132434 [==============================] - 212s 2ms/sample - loss: 2.5372\n",
            "Epoch 8/20\n",
            "132434/132434 [==============================] - 212s 2ms/sample - loss: 2.5004\n",
            "Epoch 9/20\n",
            "132434/132434 [==============================] - 212s 2ms/sample - loss: 2.4625\n",
            "Epoch 10/20\n",
            "132434/132434 [==============================] - 213s 2ms/sample - loss: 2.4315\n",
            "Epoch 11/20\n",
            "132434/132434 [==============================] - 213s 2ms/sample - loss: 2.4056\n",
            "Epoch 12/20\n",
            "132434/132434 [==============================] - 213s 2ms/sample - loss: 2.3767\n",
            "Epoch 13/20\n",
            "132434/132434 [==============================] - 214s 2ms/sample - loss: 2.3507\n",
            "Epoch 14/20\n",
            "132434/132434 [==============================] - 212s 2ms/sample - loss: 2.3298\n",
            "Epoch 15/20\n",
            "132434/132434 [==============================] - 209s 2ms/sample - loss: 2.3073\n",
            "Epoch 16/20\n",
            "132434/132434 [==============================] - 208s 2ms/sample - loss: 2.2885\n",
            "Epoch 17/20\n",
            "132434/132434 [==============================] - 211s 2ms/sample - loss: 2.2690\n",
            "Epoch 18/20\n",
            "132434/132434 [==============================] - 209s 2ms/sample - loss: 2.2521\n",
            "Epoch 19/20\n",
            "132434/132434 [==============================] - 203s 2ms/sample - loss: 2.2346\n",
            "Epoch 20/20\n",
            "132434/132434 [==============================] - 201s 2ms/sample - loss: 2.2163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe81b9edc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5iuyrs-EWMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f2f1584e-d1c2-4763-980a-b99d0910d012"
      },
      "source": [
        "start = np.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([indices_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:\n",
            "\" e unnatural; and as for the\r\n",
            "notion of his preferring wine to brandy, i entirely disbelieved it. the \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq0UVmgyFy8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ecbab440-47f3-4924-bafb-9f55a290af96"
      },
      "source": [
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(len(chars))\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = indices_char[index]\n",
        "    seq_in = [indices_char[value] for value in pattern]\n",
        "\n",
        "    sys.stdout.write(result)\n",
        "    #print(result)  this will print character line by line\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh the shoueh the \n",
            "she sooe of the shoueh the shoueh the shoueh t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uivFuqXFWrFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}